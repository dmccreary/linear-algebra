# Autonomous Systems and Sensor Fusion

## Summary

The capstone chapter applies all course concepts to the complex, safety-critical domain of autonomous vehicles and robotics. You will learn LIDAR point cloud processing, camera calibration, sensor fusion with Kalman filters, state estimation and prediction, SLAM (Simultaneous Localization and Mapping), object detection and tracking, and path planning algorithms. These are the techniques that enable self-driving cars and autonomous robots.

## Concepts Covered

This chapter covers the following 20 concepts from the learning graph:

1. LIDAR Point Cloud
2. Camera Calibration
3. Sensor Fusion
4. Kalman Filter
5. State Vector
6. Measurement Vector
7. Prediction Step
8. Update Step
9. Kalman Gain
10. Extended Kalman Filter
11. State Estimation
12. SLAM
13. Localization
14. Mapping
15. Object Detection
16. Object Tracking
17. Bounding Box
18. Path Planning
19. Motion Planning
20. Trajectory Optimization

## Prerequisites

This chapter builds on concepts from:

- [Chapter 1: Vectors and Vector Spaces](../01-vectors-and-vector-spaces/index.md)
- [Chapter 2: Matrices and Matrix Operations](../02-matrices-and-matrix-operations/index.md)
- [Chapter 10: Neural Networks and Deep Learning](../10-neural-networks-and-deep-learning/index.md)
- [Chapter 12: Optimization and Learning Algorithms](../12-optimization-and-learning-algorithms/index.md)
- [Chapter 13: Image Processing and Computer Vision](../13-image-processing-and-computer-vision/index.md)
- [Chapter 14: 3D Geometry and Transformations](../14-3d-geometry-and-transformations/index.md)

---

TODO: Generate Chapter Content
