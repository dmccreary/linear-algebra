
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Powerful matrix factorization techniques for computation, analysis, and dimensionality reduction">
      
      
        <meta name="author" content="Dan McCreary">
      
      
        <link rel="canonical" href="https://dmccreary.github.io/linear-algebra/chapters/07-matrix-decompositions/">
      
      
        <link rel="prev" href="../06-eigenvalues-and-eigenvectors/quiz/">
      
      
        <link rel="next" href="quiz/">
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Matrix Decompositions - Linear Algebra</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-KC2L3G6KXH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-KC2L3G6KXH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-KC2L3G6KXH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Matrix Decompositions - Linear Algebra" >
      
        <meta  property="og:description"  content="Powerful matrix factorization techniques for computation, analysis, and dimensionality reduction" >
      
        <meta  property="og:image"  content="https://dmccreary.github.io/linear-algebra/assets/images/social/chapters/07-matrix-decompositions/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://dmccreary.github.io/linear-algebra/chapters/07-matrix-decompositions/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Matrix Decompositions - Linear Algebra" >
      
        <meta  name="twitter:description"  content="Powerful matrix factorization techniques for computation, analysis, and dimensionality reduction" >
      
        <meta  name="twitter:image"  content="https://dmccreary.github.io/linear-algebra/assets/images/social/chapters/07-matrix-decompositions/index.png" >
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#matrix-decompositions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Linear Algebra" class="md-header__button md-logo" aria-label="Linear Algebra" data-md-component="logo">
      
  <img src="../../img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Linear Algebra
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Matrix Decompositions
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/dmccreary/linear-algebra" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Linear Algebra" class="md-nav__button md-logo" aria-label="Linear Algebra" data-md-component="logo">
      
  <img src="../../img/logo.png" alt="logo">

    </a>
    Linear Algebra
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dmccreary/linear-algebra" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course-description/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Course Description
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Chapters
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Chapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../01-vectors-and-vector-spaces/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1. Vectors and Vector Spaces
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../02-matrices-and-matrix-operations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2. Matrices and Matrix Operations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../03-systems-of-linear-equations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3. Systems of Linear Equations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../04-linear-transformations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4. Linear Transformations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../05-determinants-and-matrix-properties/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    5. Determinants and Matrix Properties
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../06-eigenvalues-and-eigenvectors/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    6. Eigenvalues and Eigenvectors
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  <span class="md-ellipsis">
    7. Matrix Decompositions
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_8">
            <span class="md-nav__icon md-icon"></span>
            7. Matrix Decompositions
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="quiz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quiz
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../08-vector-spaces-and-inner-products/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    8. Vector Spaces and Inner Products
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../09-machine-learning-foundations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    9. Machine Learning Foundations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../10-neural-networks-and-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10. Neural Networks and Deep Learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../11-generative-ai-and-llms/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11. Generative AI and LLMs
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../12-optimization-and-learning-algorithms/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12. Optimization and Learning Algorithms
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../13-image-processing-and-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13. Image Processing and Computer Vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../14-3d-geometry-and-transformations/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14. 3D Geometry and Transformations
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../15-autonomous-systems-and-sensor-fusion/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15. Autonomous Systems and Sensor Fusion
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../sims/vector-2d-3d-visualizer/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    MicroSims
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../learning-graph/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Learning Graph
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contact
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concepts-covered" class="md-nav__link">
    <span class="md-ellipsis">
      Concepts Covered
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#matrix-rank-a-foundation-for-decompositions" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Rank: A Foundation for Decompositions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Matrix Rank: A Foundation for Decompositions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#matrix-rank" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix Rank
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-matrix-rank-visualizer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Matrix Rank Visualizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lu-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      LU Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LU Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-lu-decomposition-matters" class="md-nav__link">
    <span class="md-ellipsis">
      Why LU Decomposition Matters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computing-lu-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Computing LU Decomposition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-lu-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Example: LU Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example: LU Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-lu-decomposition-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: LU Decomposition Step-by-Step
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#partial-pivoting" class="md-nav__link">
    <span class="md-ellipsis">
      Partial Pivoting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computational-cost" class="md-nav__link">
    <span class="md-ellipsis">
      Computational Cost
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cholesky-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Cholesky Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cholesky Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#positive-definite-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Positive Definite Matrix
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Positive Definite Matrix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-positive-definiteness-visualizer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Positive Definiteness Visualizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computing-cholesky-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Computing Cholesky Decomposition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-cholesky-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Cholesky Decomposition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advantages-of-cholesky" class="md-nav__link">
    <span class="md-ellipsis">
      Advantages of Cholesky
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qr-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      QR Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QR Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-qr-decomposition-matters" class="md-nav__link">
    <span class="md-ellipsis">
      Why QR Decomposition Matters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gram-schmidt-qr" class="md-nav__link">
    <span class="md-ellipsis">
      Gram-Schmidt QR
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gram-Schmidt QR">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-gram-schmidt-orthogonalization" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Gram-Schmidt Orthogonalization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#householder-qr" class="md-nav__link">
    <span class="md-ellipsis">
      Householder QR
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Householder QR">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#advantages-of-householder-qr" class="md-nav__link">
    <span class="md-ellipsis">
      Advantages of Householder QR
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Singular Value Decomposition (SVD)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-svd-components" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding SVD Components
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding SVD Components">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#singular-values" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#left-singular-vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Left Singular Vectors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#right-singular-vectors" class="md-nav__link">
    <span class="md-ellipsis">
      Right Singular Vectors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-svd-geometry" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: SVD Geometry
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-fundamental-picture" class="md-nav__link">
    <span class="md-ellipsis">
      The Fundamental Picture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-svd-vs-compact-svd-vs-truncated-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Full SVD vs. Compact SVD vs. Truncated SVD
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Full SVD vs. Compact SVD vs. Truncated SVD">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#full-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Full SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compact-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Compact SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#truncated-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Truncated SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-svd-forms-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: SVD Forms Comparison
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computing-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Computing SVD
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-rank-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Rank Approximation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Low-Rank Approximation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-eckart-young-theorem" class="md-nav__link">
    <span class="md-ellipsis">
      The Eckart-Young Theorem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-image-compression-with-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Image Compression with SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications-of-low-rank-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Applications of Low-Rank Approximation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#numerical-rank-and-condition-number" class="md-nav__link">
    <span class="md-ellipsis">
      Numerical Rank and Condition Number
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Numerical Rank and Condition Number">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numerical-rank" class="md-nav__link">
    <span class="md-ellipsis">
      Numerical Rank
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#condition-number" class="md-nav__link">
    <span class="md-ellipsis">
      Condition Number
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Condition Number">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#interpretation" class="md-nav__link">
    <span class="md-ellipsis">
      Interpretation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagram-condition-number-visualizer" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Condition Number Visualizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#improving-conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      Improving Conditioning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#choosing-the-right-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Choosing the Right Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Choosing the Right Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diagram-decomposition-decision-tree" class="md-nav__link">
    <span class="md-ellipsis">
      Diagram: Decomposition Decision Tree
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implementation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/dmccreary/linear-algebra/edit/master/docs/chapters/07-matrix-decompositions/index.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="matrix-decompositions">Matrix Decompositions</h1>
<h2 id="summary">Summary</h2>
<p>Matrix factorizations provide powerful tools for analysis, computation, and dimensionality reduction. This chapter covers LU, QR, Cholesky, and Singular Value Decomposition (SVD). Each decomposition has specific use cases: LU for solving systems efficiently, QR for least squares problems, Cholesky for symmetric positive definite matrices, and SVD for low-rank approximations and recommender systems.</p>
<h2 id="concepts-covered">Concepts Covered</h2>
<p>This chapter covers the following 19 concepts from the learning graph:</p>
<ol>
<li>Matrix Factorization</li>
<li>LU Decomposition</li>
<li>Partial Pivoting</li>
<li>QR Decomposition</li>
<li>Gram-Schmidt QR</li>
<li>Householder QR</li>
<li>Cholesky Decomposition</li>
<li>Positive Definite Matrix</li>
<li>SVD</li>
<li>Singular Value</li>
<li>Left Singular Vector</li>
<li>Right Singular Vector</li>
<li>Full SVD</li>
<li>Compact SVD</li>
<li>Truncated SVD</li>
<li>Low-Rank Approximation</li>
<li>Matrix Rank</li>
<li>Numerical Rank</li>
<li>Condition Number</li>
</ol>
<h2 id="prerequisites">Prerequisites</h2>
<p>This chapter builds on concepts from:</p>
<ul>
<li><a href="../02-matrices-and-matrix-operations/">Chapter 2: Matrices and Matrix Operations</a></li>
<li><a href="../03-systems-of-linear-equations/">Chapter 3: Systems of Linear Equations</a></li>
<li><a href="../04-linear-transformations/">Chapter 4: Linear Transformations</a></li>
<li><a href="../06-eigenvalues-and-eigenvectors/">Chapter 6: Eigenvalues and Eigenvectors</a></li>
<li><a href="../08-vector-spaces-and-inner-products/">Chapter 8: Vector Spaces and Inner Products</a> (for Gram-Schmidt)</li>
</ul>
<hr />
<h2 id="introduction">Introduction</h2>
<p>Just as integers can be factored into primes to reveal their structure, matrices can be decomposed into products of simpler matrices. These <strong>matrix factorizations</strong> expose the underlying structure of linear transformations, enable efficient computation, and provide geometric insight into how matrices act on vectors.</p>
<p>Matrix decompositions are the workhorses of numerical linear algebra. When you solve a system of linear equations, compute a least-squares fit, reduce dimensionality with PCA, or build a recommender system, you are using matrix decompositions behind the scenes. Understanding these factorizations—when to use each one and what makes them numerically stable—is essential for any practitioner working with data.</p>
<p>This chapter covers four major decompositions, each with distinct purposes:</p>
<table>
<thead>
<tr>
<th>Decomposition</th>
<th>Form</th>
<th>Primary Use Cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>LU</td>
<td><span class="arithmatex">\(A = LU\)</span></td>
<td>Solving systems, computing determinants</td>
</tr>
<tr>
<td>QR</td>
<td><span class="arithmatex">\(A = QR\)</span></td>
<td>Least squares, eigenvalue algorithms</td>
</tr>
<tr>
<td>Cholesky</td>
<td><span class="arithmatex">\(A = LL^T\)</span></td>
<td>Symmetric positive definite systems</td>
</tr>
<tr>
<td>SVD</td>
<td><span class="arithmatex">\(A = U\Sigma V^T\)</span></td>
<td>Low-rank approximation, dimensionality reduction</td>
</tr>
</tbody>
</table>
<h2 id="matrix-rank-a-foundation-for-decompositions">Matrix Rank: A Foundation for Decompositions</h2>
<p>Before diving into specific decompositions, we need to understand <strong>matrix rank</strong>, which fundamentally determines what decompositions are possible and their properties.</p>
<h4 id="matrix-rank">Matrix Rank</h4>
<p>The <strong>rank</strong> of a matrix <span class="arithmatex">\(A\)</span> is the dimension of its column space (equivalently, its row space):</p>
<p><span class="arithmatex">\(\text{rank}(A) = \dim(\text{col}(A)) = \dim(\text{row}(A))\)</span></p>
<p>For an <span class="arithmatex">\(m \times n\)</span> matrix:</p>
<ul>
<li><span class="arithmatex">\(\text{rank}(A) \leq \min(m, n)\)</span></li>
<li>If <span class="arithmatex">\(\text{rank}(A) = \min(m, n)\)</span>, the matrix has <strong>full rank</strong></li>
<li>If <span class="arithmatex">\(\text{rank}(A) &lt; \min(m, n)\)</span>, the matrix is <strong>rank-deficient</strong></li>
</ul>
<p>The rank tells us how many linearly independent columns (or rows) the matrix contains, which directly impacts the uniqueness of solutions to linear systems and the structure of decompositions.</p>
<h4 id="diagram-matrix-rank-visualizer">Diagram: Matrix Rank Visualizer</h4>
<iframe src="../../sims/matrix-rank-visualizer/main.html" height="552px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/matrix-rank-visualizer/main.html">Run the Matrix Rank Visualizer Fullscreen</a></p>
<details>
<summary>Matrix Rank Visualizer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Understand</p>
<p>Learning Objective: Visualize how matrix rank relates to the column space and understand rank-deficient matrices geometrically</p>
<p>Visual elements:
- Left panel: 3x3 matrix input with editable values
- Center panel: 3D visualization showing column vectors as arrows from origin
- Column space displayed as a plane (rank 2) or line (rank 1) or point (rank 0)
- Right panel: Row echelon form showing pivot positions</p>
<p>Interactive controls:
- Matrix entry fields (3x3)
- "Compute Rank" button
- Toggle to show/hide individual column vectors
- Toggle to show column space as shaded region
- Preset examples dropdown (full rank, rank 2, rank 1)
- Animation to show column reduction</p>
<p>Default parameters:
- Matrix A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] (rank 2)
- Canvas: responsive, minimum 900x500px</p>
<p>Behavior:
- Real-time rank computation as matrix values change
- Highlight linearly dependent columns
- Show column space dimension visually
- Display row echelon form with pivot columns highlighted
- Animate transition when rank changes</p>
<p>Implementation: p5.js with WEBGL for 3D visualization</p>
</details>
<h2 id="lu-decomposition">LU Decomposition</h2>
<p><strong>LU Decomposition</strong> factors a square matrix into the product of a lower triangular matrix <span class="arithmatex">\(L\)</span> and an upper triangular matrix <span class="arithmatex">\(U\)</span>:</p>
<p><span class="arithmatex">\(A = LU\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(L\)</span> is lower triangular with 1s on the diagonal</li>
<li><span class="arithmatex">\(U\)</span> is upper triangular</li>
</ul>
<p>This decomposition essentially records the steps of Gaussian elimination in matrix form.</p>
<h3 id="why-lu-decomposition-matters">Why LU Decomposition Matters</h3>
<p>LU decomposition transforms the problem of solving <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span> into two simpler triangular systems:</p>
<ol>
<li>Solve <span class="arithmatex">\(L\mathbf{y} = \mathbf{b}\)</span> for <span class="arithmatex">\(\mathbf{y}\)</span> (forward substitution)</li>
<li>Solve <span class="arithmatex">\(U\mathbf{x} = \mathbf{y}\)</span> for <span class="arithmatex">\(\mathbf{x}\)</span> (back substitution)</li>
</ol>
<p>Each triangular solve takes only <span class="arithmatex">\(O(n^2)\)</span> operations, compared to <span class="arithmatex">\(O(n^3)\)</span> for the original system. The key advantage is that once we have computed the LU factorization (which costs <span class="arithmatex">\(O(n^3)\)</span>), we can solve for multiple right-hand sides <span class="arithmatex">\(\mathbf{b}_1, \mathbf{b}_2, \ldots\)</span> with only <span class="arithmatex">\(O(n^2)\)</span> additional work each.</p>
<h3 id="computing-lu-decomposition">Computing LU Decomposition</h3>
<p>The algorithm follows Gaussian elimination, but instead of modifying the right-hand side, we store the multipliers:</p>
<ol>
<li>For each column <span class="arithmatex">\(k = 1, \ldots, n-1\)</span>:</li>
<li>
<p>For each row <span class="arithmatex">\(i = k+1, \ldots, n\)</span>:</p>
<ul>
<li>Compute multiplier: <span class="arithmatex">\(l_{ik} = a_{ik}/a_{kk}\)</span></li>
<li>Eliminate: <span class="arithmatex">\(a_{ij} \leftarrow a_{ij} - l_{ik} \cdot a_{kj}\)</span> for <span class="arithmatex">\(j = k, \ldots, n\)</span></li>
</ul>
</li>
<li>
<p>The multipliers form <span class="arithmatex">\(L\)</span>, and the reduced matrix becomes <span class="arithmatex">\(U\)</span></p>
</li>
</ol>
<h3 id="example-lu-decomposition">Example: LU Decomposition</h3>
<p>Consider the matrix:</p>
<p><span class="arithmatex">\(A = \begin{bmatrix} 2 &amp; 1 &amp; 1 \\ 4 &amp; 3 &amp; 3 \\ 8 &amp; 7 &amp; 9 \end{bmatrix}\)</span></p>
<p><strong>Step 1:</strong> Eliminate below the first pivot (2):</p>
<ul>
<li>Multiplier for row 2: <span class="arithmatex">\(l_{21} = 4/2 = 2\)</span></li>
<li>Multiplier for row 3: <span class="arithmatex">\(l_{31} = 8/2 = 4\)</span></li>
</ul>
<p>After elimination:</p>
<p><span class="arithmatex">\(\begin{bmatrix} 2 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 3 &amp; 5 \end{bmatrix}\)</span></p>
<p><strong>Step 2:</strong> Eliminate below the second pivot (1):</p>
<ul>
<li>Multiplier for row 3: <span class="arithmatex">\(l_{32} = 3/1 = 3\)</span></li>
</ul>
<p>After elimination:</p>
<p><span class="arithmatex">\(U = \begin{bmatrix} 2 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 2 \end{bmatrix}\)</span></p>
<p>The multipliers form <span class="arithmatex">\(L\)</span>:</p>
<p><span class="arithmatex">\(L = \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 2 &amp; 1 &amp; 0 \\ 4 &amp; 3 &amp; 1 \end{bmatrix}\)</span></p>
<p>You can verify: <span class="arithmatex">\(LU = A\)</span>.</p>
<h4 id="diagram-lu-decomposition-step-by-step">Diagram: LU Decomposition Step-by-Step</h4>
<iframe src="../../sims/lu-decomposition/main.html" height="502px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/lu-decomposition/main.html">Run the LU Decomposition Visualizer Fullscreen</a></p>
<details>
<summary>LU Decomposition Algorithm Visualizer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Apply</p>
<p>Learning Objective: Understand the LU decomposition algorithm by watching elimination steps and multiplier storage</p>
<p>Visual elements:
- Left panel: Original matrix A with current state
- Center panel: L matrix being built (showing multipliers)
- Right panel: U matrix being formed (showing elimination)
- Highlight current pivot element
- Arrows showing elimination operations
- Step counter and description</p>
<p>Interactive controls:
- Matrix size selector (2x2, 3x3, 4x4)
- Matrix entry fields
- "Next Step" button for manual stepping
- "Auto Run" button with speed slider
- "Reset" button
- "Verify LU = A" button</p>
<p>Default parameters:
- 3x3 matrix mode
- Matrix A = [[2, 1, 1], [4, 3, 3], [8, 7, 9]]
- Canvas: responsive</p>
<p>Behavior:
- Highlight current pivot in yellow
- Highlight elements being eliminated in red
- Show multiplier calculation
- Animate row operations
- Display running product L×U for verification
- Warning if zero pivot encountered (needs pivoting)</p>
<p>Implementation: p5.js with matrix animation</p>
</details>
<h3 id="partial-pivoting">Partial Pivoting</h3>
<p>The basic LU decomposition fails when a pivot element is zero, and becomes numerically unstable when pivots are small. <strong>Partial pivoting</strong> addresses this by swapping rows to bring the largest element in the column to the pivot position.</p>
<p>With partial pivoting, we compute:</p>
<p><span class="arithmatex">\(PA = LU\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(P\)</span> is a permutation matrix recording the row swaps</li>
<li><span class="arithmatex">\(L\)</span> is lower triangular with entries <span class="arithmatex">\(|l_{ij}| \leq 1\)</span></li>
<li><span class="arithmatex">\(U\)</span> is upper triangular</li>
</ul>
<p>The permutation matrix <span class="arithmatex">\(P\)</span> is orthogonal (<span class="arithmatex">\(P^{-1} = P^T\)</span>), so solving <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span> becomes:</p>
<ol>
<li>Compute <span class="arithmatex">\(P\mathbf{b}\)</span> (apply row permutations)</li>
<li>Solve <span class="arithmatex">\(L\mathbf{y} = P\mathbf{b}\)</span></li>
<li>Solve <span class="arithmatex">\(U\mathbf{x} = \mathbf{y}\)</span></li>
</ol>
<div class="admonition warning">
<p class="admonition-title">Numerical Stability</p>
<p>Always use partial pivoting in practice. Without it, even small rounding errors can be amplified catastrophically. Most numerical libraries (LAPACK, NumPy) use partial pivoting by default.</p>
</div>
<h3 id="computational-cost">Computational Cost</h3>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>LU factorization</td>
<td><span class="arithmatex">\(\frac{2}{3}n^3\)</span> flops</td>
</tr>
<tr>
<td>Forward substitution</td>
<td><span class="arithmatex">\(n^2\)</span> flops</td>
</tr>
<tr>
<td>Back substitution</td>
<td><span class="arithmatex">\(n^2\)</span> flops</td>
</tr>
<tr>
<td>Total for one solve</td>
<td><span class="arithmatex">\(\frac{2}{3}n^3 + 2n^2\)</span> flops</td>
</tr>
<tr>
<td>Additional solves</td>
<td><span class="arithmatex">\(2n^2\)</span> flops each</td>
</tr>
</tbody>
</table>
<h2 id="cholesky-decomposition">Cholesky Decomposition</h2>
<p>For <strong>symmetric positive definite</strong> matrices, we can use a more efficient and stable decomposition called <strong>Cholesky decomposition</strong>:</p>
<p><span class="arithmatex">\(A = LL^T\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(A\)</span> is symmetric (<span class="arithmatex">\(A = A^T\)</span>) and positive definite</li>
<li><span class="arithmatex">\(L\)</span> is lower triangular with positive diagonal entries</li>
</ul>
<h3 id="positive-definite-matrix">Positive Definite Matrix</h3>
<p>A symmetric matrix <span class="arithmatex">\(A\)</span> is <strong>positive definite</strong> if:</p>
<p><span class="arithmatex">\(\mathbf{x}^T A \mathbf{x} &gt; 0 \quad \text{for all } \mathbf{x} \neq \mathbf{0}\)</span></p>
<p>Equivalent characterizations:</p>
<ul>
<li>All eigenvalues of <span class="arithmatex">\(A\)</span> are positive</li>
<li>All leading principal minors are positive</li>
<li><span class="arithmatex">\(A\)</span> can be written as <span class="arithmatex">\(A = B^TB\)</span> for some matrix <span class="arithmatex">\(B\)</span> with full column rank</li>
<li>The Cholesky decomposition exists</li>
</ul>
<p>Positive definite matrices arise frequently in applications:</p>
<ul>
<li>Covariance matrices in statistics</li>
<li>Gram matrices <span class="arithmatex">\(X^TX\)</span> in machine learning</li>
<li>Hessians of convex functions at minima</li>
<li>Stiffness matrices in finite element analysis</li>
</ul>
<table>
<thead>
<tr>
<th>Property</th>
<th>Positive Definite</th>
<th>Positive Semi-Definite</th>
</tr>
</thead>
<tbody>
<tr>
<td>Eigenvalues</td>
<td>All <span class="arithmatex">\(&gt; 0\)</span></td>
<td>All <span class="arithmatex">\(\geq 0\)</span></td>
</tr>
<tr>
<td>Quadratic form</td>
<td><span class="arithmatex">\(\mathbf{x}^TA\mathbf{x} &gt; 0\)</span> for <span class="arithmatex">\(\mathbf{x} \neq 0\)</span></td>
<td><span class="arithmatex">\(\mathbf{x}^TA\mathbf{x} \geq 0\)</span> for all <span class="arithmatex">\(\mathbf{x}\)</span></td>
</tr>
<tr>
<td>Invertibility</td>
<td>Always invertible</td>
<td>May be singular</td>
</tr>
<tr>
<td>Cholesky</td>
<td>Unique <span class="arithmatex">\(LL^T\)</span> exists</td>
<td><span class="arithmatex">\(LL^T\)</span> exists but <span class="arithmatex">\(L\)</span> may have zeros</td>
</tr>
</tbody>
</table>
<h4 id="diagram-positive-definiteness-visualizer">Diagram: Positive Definiteness Visualizer</h4>
<iframe src="../../sims/positive-definiteness/main.html" height="552px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/positive-definiteness/main.html">Run the Positive Definiteness Visualizer Fullscreen</a></p>
<details>
<summary>Positive Definiteness Visualizer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Understand</p>
<p>Learning Objective: Visualize the quadratic form <span class="arithmatex">\(\mathbf{x}^T A \mathbf{x}\)</span> and understand how positive definiteness relates to the shape of the surface</p>
<p>Visual elements:
- Left panel: 2x2 symmetric matrix input
- Center panel: 3D surface plot of <span class="arithmatex">\(f(x,y) = [x, y] A [x, y]^T\)</span>
- Eigenvalue display with color coding (positive=green, negative=red)
- Level curves (contour plot) below 3D surface
- Classification label: "Positive Definite", "Negative Definite", "Indefinite", "Positive Semi-Definite"</p>
<p>Interactive controls:
- Matrix entry fields (symmetric: entering a₁₂ sets a₂₁)
- Rotation controls for 3D view
- Toggle contour lines
- Preset examples: positive definite, negative definite, indefinite, semi-definite</p>
<p>Default parameters:
- Matrix A = [[3, 1], [1, 2]] (positive definite)
- Surface plot range: x, y ∈ [-2, 2]
- Canvas: responsive</p>
<p>Behavior:
- Real-time surface update as matrix changes
- Color surface by height (red for negative, green for positive)
- Show eigenvalues and eigenvector directions on contour plot
- Highlight minimum point for positive definite matrices
- Saddle point visualization for indefinite matrices</p>
<p>Implementation: p5.js with WEBGL for 3D surface rendering</p>
</details>
<h3 id="computing-cholesky-decomposition">Computing Cholesky Decomposition</h3>
<p>The Cholesky algorithm computes <span class="arithmatex">\(L\)</span> column by column:</p>
<p>For <span class="arithmatex">\(j = 1, \ldots, n\)</span>:</p>
<p><span class="arithmatex">\(l_{jj} = \sqrt{a_{jj} - \sum_{k=1}^{j-1} l_{jk}^2}\)</span></p>
<p>For <span class="arithmatex">\(i = j+1, \ldots, n\)</span>:</p>
<p><span class="arithmatex">\(l_{ij} = \frac{1}{l_{jj}}\left(a_{ij} - \sum_{k=1}^{j-1} l_{ik}l_{jk}\right)\)</span></p>
<h3 id="example-cholesky-decomposition">Example: Cholesky Decomposition</h3>
<p>Consider the positive definite matrix:</p>
<p><span class="arithmatex">\(A = \begin{bmatrix} 4 &amp; 2 &amp; 2 \\ 2 &amp; 5 &amp; 1 \\ 2 &amp; 1 &amp; 6 \end{bmatrix}\)</span></p>
<p><strong>Column 1:</strong></p>
<ul>
<li><span class="arithmatex">\(l_{11} = \sqrt{4} = 2\)</span></li>
<li><span class="arithmatex">\(l_{21} = 2/2 = 1\)</span></li>
<li><span class="arithmatex">\(l_{31} = 2/2 = 1\)</span></li>
</ul>
<p><strong>Column 2:</strong></p>
<ul>
<li><span class="arithmatex">\(l_{22} = \sqrt{5 - 1^2} = \sqrt{4} = 2\)</span></li>
<li><span class="arithmatex">\(l_{32} = (1 - 1 \cdot 1)/2 = 0\)</span></li>
</ul>
<p><strong>Column 3:</strong></p>
<ul>
<li><span class="arithmatex">\(l_{33} = \sqrt{6 - 1^2 - 0^2} = \sqrt{5}\)</span></li>
</ul>
<p>Result:</p>
<p><span class="arithmatex">\(L = \begin{bmatrix} 2 &amp; 0 &amp; 0 \\ 1 &amp; 2 &amp; 0 \\ 1 &amp; 0 &amp; \sqrt{5} \end{bmatrix}\)</span></p>
<h3 id="advantages-of-cholesky">Advantages of Cholesky</h3>
<ul>
<li><strong>Half the work:</strong> Cholesky requires <span class="arithmatex">\(\frac{1}{3}n^3\)</span> flops vs. <span class="arithmatex">\(\frac{2}{3}n^3\)</span> for LU</li>
<li><strong>No pivoting needed:</strong> Positive definiteness guarantees numerical stability</li>
<li><strong>Natural for applications:</strong> Covariance matrices and Gram matrices are positive semi-definite</li>
</ul>
<h2 id="qr-decomposition">QR Decomposition</h2>
<p><strong>QR Decomposition</strong> factors a matrix into an orthogonal matrix <span class="arithmatex">\(Q\)</span> and an upper triangular matrix <span class="arithmatex">\(R\)</span>:</p>
<p><span class="arithmatex">\(A = QR\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(Q\)</span> is orthogonal (<span class="arithmatex">\(Q^TQ = I\)</span>, columns form orthonormal basis)</li>
<li><span class="arithmatex">\(R\)</span> is upper triangular</li>
</ul>
<p>For an <span class="arithmatex">\(m \times n\)</span> matrix with <span class="arithmatex">\(m \geq n\)</span>:
- Full QR: <span class="arithmatex">\(Q\)</span> is <span class="arithmatex">\(m \times m\)</span>, <span class="arithmatex">\(R\)</span> is <span class="arithmatex">\(m \times n\)</span>
- Reduced QR: <span class="arithmatex">\(Q\)</span> is <span class="arithmatex">\(m \times n\)</span>, <span class="arithmatex">\(R\)</span> is <span class="arithmatex">\(n \times n\)</span></p>
<h3 id="why-qr-decomposition-matters">Why QR Decomposition Matters</h3>
<p>QR decomposition is the foundation of:</p>
<ol>
<li><strong>Least squares problems:</strong> Solving <span class="arithmatex">\(A\mathbf{x} \approx \mathbf{b}\)</span> in the overdetermined case</li>
<li><strong>QR algorithm:</strong> The standard method for computing eigenvalues</li>
<li><strong>Orthogonalization:</strong> Creating orthonormal bases from arbitrary vectors</li>
</ol>
<p>For least squares, the normal equations <span class="arithmatex">\(A^TA\mathbf{x} = A^T\mathbf{b}\)</span> can have numerical issues. Using QR, we instead solve:</p>
<p><span class="arithmatex">\(R\mathbf{x} = Q^T\mathbf{b}\)</span></p>
<p>which is numerically stable because <span class="arithmatex">\(Q\)</span> preserves norms.</p>
<h3 id="gram-schmidt-qr">Gram-Schmidt QR</h3>
<p>The <strong>Gram-Schmidt process</strong> constructs <span class="arithmatex">\(Q\)</span> by orthonormalizing the columns of <span class="arithmatex">\(A\)</span> one at a time:</p>
<p>For <span class="arithmatex">\(j = 1, \ldots, n\)</span>:</p>
<ol>
<li>Start with column <span class="arithmatex">\(\mathbf{a}_j\)</span></li>
<li>Subtract projections onto previous <span class="arithmatex">\(\mathbf{q}\)</span> vectors:
   <span class="arithmatex">\(\mathbf{v}_j = \mathbf{a}_j - \sum_{i=1}^{j-1} (\mathbf{q}_i^T \mathbf{a}_j) \mathbf{q}_i\)</span></li>
<li>Normalize: <span class="arithmatex">\(\mathbf{q}_j = \mathbf{v}_j / \|\mathbf{v}_j\|\)</span></li>
</ol>
<p>The coefficients form the upper triangular matrix <span class="arithmatex">\(R\)</span>:</p>
<ul>
<li><span class="arithmatex">\(r_{ij} = \mathbf{q}_i^T \mathbf{a}_j\)</span> for <span class="arithmatex">\(i &lt; j\)</span></li>
<li><span class="arithmatex">\(r_{jj} = \|\mathbf{v}_j\|\)</span></li>
</ul>
<h4 id="diagram-gram-schmidt-orthogonalization">Diagram: Gram-Schmidt Orthogonalization</h4>
<iframe src="../../sims/gram-schmidt/main.html" height="552px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/gram-schmidt/main.html">Run the Gram-Schmidt Visualizer Fullscreen</a></p>
<details>
<summary>Gram-Schmidt Process Visualizer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Apply</p>
<p>Learning Objective: Understand how Gram-Schmidt creates orthonormal vectors by visualizing the projection and subtraction steps</p>
<p>Visual elements:
- 3D coordinate system
- Original vectors a₁, a₂, a₃ as colored arrows
- Orthonormal vectors q₁, q₂, q₃ as they are computed
- Projection vectors showing what is subtracted
- Right-angle indicators between orthogonal vectors</p>
<p>Interactive controls:
- Input matrix A (3 columns, 3 rows for 3D visualization)
- "Step" button to advance one orthonormalization step
- "Run All" button for complete animation
- "Reset" button
- Speed slider
- Toggle to show/hide projection components</p>
<p>Default parameters:
- Matrix A with 3 linearly independent columns
- Canvas: responsive 3D view</p>
<p>Behavior:
- Show each projection step clearly
- Animate subtraction of projection
- Show normalization step
- Display current q vector and r values
- Highlight orthogonality with right-angle symbols
- Warning if vectors are nearly linearly dependent</p>
<p>Implementation: p5.js with WEBGL for 3D rendering</p>
</details>
<div class="admonition note">
<p class="admonition-title">Classical vs. Modified Gram-Schmidt</p>
<p>The classical Gram-Schmidt algorithm described above can lose orthogonality due to rounding errors. The modified Gram-Schmidt algorithm recomputes projections against the updated vectors rather than original vectors, providing better numerical stability.</p>
</div>
<h3 id="householder-qr">Householder QR</h3>
<p><strong>Householder QR</strong> uses orthogonal reflections (Householder transformations) to zero out elements below the diagonal. Each Householder matrix has the form:</p>
<p><span class="arithmatex">\(H = I - 2\mathbf{v}\mathbf{v}^T\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(\mathbf{v}\)</span> is a unit vector defining the reflection plane</li>
<li><span class="arithmatex">\(H\)</span> is orthogonal and symmetric (<span class="arithmatex">\(H = H^T = H^{-1}\)</span>)</li>
</ul>
<p>The algorithm applies successive Householder reflections:</p>
<p><span class="arithmatex">\(H_n \cdots H_2 H_1 A = R\)</span></p>
<p>Therefore:</p>
<p><span class="arithmatex">\(Q = H_1 H_2 \cdots H_n\)</span></p>
<h4 id="advantages-of-householder-qr">Advantages of Householder QR</h4>
<ul>
<li><strong>Numerically stable:</strong> Each transformation is exactly orthogonal</li>
<li><strong>Efficient storage:</strong> Only need to store reflection vectors <span class="arithmatex">\(\mathbf{v}\)</span></li>
<li><strong>Standard choice:</strong> Used by LAPACK and all major numerical libraries</li>
</ul>
<table>
<thead>
<tr>
<th>Method</th>
<th>Stability</th>
<th>Flops</th>
<th>Storage</th>
</tr>
</thead>
<tbody>
<tr>
<td>Classical Gram-Schmidt</td>
<td>Poor</td>
<td><span class="arithmatex">\(2mn^2\)</span></td>
<td><span class="arithmatex">\(mn + n^2\)</span></td>
</tr>
<tr>
<td>Modified Gram-Schmidt</td>
<td>Good</td>
<td><span class="arithmatex">\(2mn^2\)</span></td>
<td><span class="arithmatex">\(mn + n^2\)</span></td>
</tr>
<tr>
<td>Householder</td>
<td>Excellent</td>
<td><span class="arithmatex">\(2mn^2 - \frac{2}{3}n^3\)</span></td>
<td><span class="arithmatex">\(mn\)</span> (compact)</td>
</tr>
</tbody>
</table>
<h2 id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)</h2>
<p>The <strong>Singular Value Decomposition</strong> is perhaps the most important and versatile matrix decomposition. It applies to any <span class="arithmatex">\(m \times n\)</span> matrix (not just square matrices):</p>
<p><span class="arithmatex">\(A = U\Sigma V^T\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(U\)</span> is an <span class="arithmatex">\(m \times m\)</span> orthogonal matrix (left singular vectors)</li>
<li><span class="arithmatex">\(\Sigma\)</span> is an <span class="arithmatex">\(m \times n\)</span> diagonal matrix (singular values)</li>
<li><span class="arithmatex">\(V\)</span> is an <span class="arithmatex">\(n \times n\)</span> orthogonal matrix (right singular vectors)</li>
</ul>
<h3 id="understanding-svd-components">Understanding SVD Components</h3>
<h4 id="singular-values">Singular Values</h4>
<p>The <strong>singular values</strong> <span class="arithmatex">\(\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r &gt; 0\)</span> are the diagonal entries of <span class="arithmatex">\(\Sigma\)</span>, where <span class="arithmatex">\(r = \text{rank}(A)\)</span>. They measure how much the matrix stretches vectors in each principal direction.</p>
<p>Key relationships:</p>
<ul>
<li><span class="arithmatex">\(\sigma_i = \sqrt{\lambda_i(A^TA)} = \sqrt{\lambda_i(AA^T)}\)</span> (singular values are square roots of eigenvalues)</li>
<li><span class="arithmatex">\(\|A\|_2 = \sigma_1\)</span> (spectral norm is largest singular value)</li>
<li><span class="arithmatex">\(\|A\|_F = \sqrt{\sum_i \sigma_i^2}\)</span> (Frobenius norm)</li>
</ul>
<h4 id="left-singular-vectors">Left Singular Vectors</h4>
<p>The columns of <span class="arithmatex">\(U\)</span> are <strong>left singular vectors</strong>. They form an orthonormal basis for the column space (first <span class="arithmatex">\(r\)</span> vectors) and left null space (remaining vectors) of <span class="arithmatex">\(A\)</span>.</p>
<p><span class="arithmatex">\(A\mathbf{v}_i = \sigma_i \mathbf{u}_i\)</span></p>
<h4 id="right-singular-vectors">Right Singular Vectors</h4>
<p>The columns of <span class="arithmatex">\(V\)</span> are <strong>right singular vectors</strong>. They form an orthonormal basis for the row space (first <span class="arithmatex">\(r\)</span> vectors) and null space (remaining vectors) of <span class="arithmatex">\(A\)</span>.</p>
<p><span class="arithmatex">\(A^T\mathbf{u}_i = \sigma_i \mathbf{v}_i\)</span></p>
<h4 id="diagram-svd-geometry">Diagram: SVD Geometry</h4>
<iframe src="../../sims/svd-geometry/main.html" height="452px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/svd-geometry/main.html">Run the SVD Geometry Visualizer Fullscreen</a></p>
<details>
<summary>SVD Geometric Interpretation</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Analyze</p>
<p>Learning Objective: Visualize SVD as a sequence of rotation, scaling, and rotation operations on the unit sphere</p>
<p>Visual elements:
- Four panels showing transformation stages:
  1. Original unit circle/sphere
  2. After V^T rotation (aligns with principal axes)
  3. After Σ scaling (ellipse with σ₁, σ₂ semi-axes)
  4. After U rotation (final orientation)
- Matrix display showing A = UΣV^T
- Singular values displayed as axis lengths</p>
<p>Interactive controls:
- 2x2 or 2x3 matrix input for A
- "Animate Transformation" button showing step-by-step
- Slider to interpolate between stages
- Toggle to show/hide singular vectors
- Toggle 2D (circle→ellipse) vs 3D (sphere→ellipsoid)</p>
<p>Default parameters:
- Matrix A = [[3, 1], [1, 3]]
- Animation duration: 2 seconds per stage
- Canvas: responsive</p>
<p>Behavior:
- Show unit circle transforming to ellipse
- Label semi-axes with singular values
- Show right singular vectors as directions on original circle
- Show left singular vectors as directions on transformed ellipse
- Display matrix factorization alongside visualization</p>
<p>Implementation: p5.js with smooth animation transitions</p>
</details>
<h3 id="the-fundamental-picture">The Fundamental Picture</h3>
<p>The SVD reveals the geometry of any linear transformation:</p>
<ol>
<li><span class="arithmatex">\(V^T\)</span> rotates the input space to align with the principal axes</li>
<li><span class="arithmatex">\(\Sigma\)</span> stretches/compresses along each axis by the singular values</li>
<li><span class="arithmatex">\(U\)</span> rotates the output space to the final orientation</li>
</ol>
<p>This decomposition exposes the four fundamental subspaces:</p>
<table>
<thead>
<tr>
<th>Subspace</th>
<th>Dimension</th>
<th>Basis from SVD</th>
</tr>
</thead>
<tbody>
<tr>
<td>Column space</td>
<td><span class="arithmatex">\(r\)</span></td>
<td>First <span class="arithmatex">\(r\)</span> columns of <span class="arithmatex">\(U\)</span></td>
</tr>
<tr>
<td>Left null space</td>
<td><span class="arithmatex">\(m - r\)</span></td>
<td>Last <span class="arithmatex">\(m - r\)</span> columns of <span class="arithmatex">\(U\)</span></td>
</tr>
<tr>
<td>Row space</td>
<td><span class="arithmatex">\(r\)</span></td>
<td>First <span class="arithmatex">\(r\)</span> columns of <span class="arithmatex">\(V\)</span></td>
</tr>
<tr>
<td>Null space</td>
<td><span class="arithmatex">\(n - r\)</span></td>
<td>Last <span class="arithmatex">\(n - r\)</span> columns of <span class="arithmatex">\(V\)</span></td>
</tr>
</tbody>
</table>
<h3 id="full-svd-vs-compact-svd-vs-truncated-svd">Full SVD vs. Compact SVD vs. Truncated SVD</h3>
<p>There are three forms of SVD depending on how we handle zero singular values:</p>
<h4 id="full-svd">Full SVD</h4>
<p>The <strong>full SVD</strong> includes all <span class="arithmatex">\(m\)</span> left singular vectors and all <span class="arithmatex">\(n\)</span> right singular vectors:</p>
<p><span class="arithmatex">\(A = U_{m \times m} \Sigma_{m \times n} V^T_{n \times n}\)</span></p>
<h4 id="compact-svd">Compact SVD</h4>
<p>The <strong>compact (reduced) SVD</strong> keeps only the <span class="arithmatex">\(r\)</span> non-zero singular values and their vectors:</p>
<p><span class="arithmatex">\(A = U_{m \times r} \Sigma_{r \times r} V^T_{r \times n}\)</span></p>
<p>This is more memory-efficient and is what NumPy's <code>np.linalg.svd(full_matrices=False)</code> returns.</p>
<h4 id="truncated-svd">Truncated SVD</h4>
<p>The <strong>truncated SVD</strong> keeps only the <span class="arithmatex">\(k\)</span> largest singular values (where <span class="arithmatex">\(k &lt; r\)</span>):</p>
<p><span class="arithmatex">\(A_k = U_{m \times k} \Sigma_{k \times k} V^T_{k \times n}\)</span></p>
<p>This gives the best rank-<span class="arithmatex">\(k\)</span> approximation to <span class="arithmatex">\(A\)</span> (Eckart-Young theorem).</p>
<h4 id="diagram-svd-forms-comparison">Diagram: SVD Forms Comparison</h4>
<iframe src="../../sims/svd-forms-comparison/main.html" height="552px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/svd-forms-comparison/main.html">Run the SVD Forms Comparison Fullscreen</a></p>
<details>
<summary>SVD Forms Comparison</summary>
<p>Type: infographic</p>
<p>Bloom Taxonomy Level: Analyze</p>
<p>Learning Objective: Compare full, compact, and truncated SVD visually and understand when to use each form</p>
<p>Layout: Three columns showing matrix dimensions for each SVD form</p>
<p>Sections:
1. "Full SVD" column
   - Matrix dimensions: U(m×m), Σ(m×n), V^T(n×n)
   - Visual: Full-size matrices with zero padding shown
   - Use case: Complete basis for all four fundamental subspaces
   - Memory: O(m² + mn + n²)</p>
<ol>
<li>"Compact SVD" column</li>
<li>Matrix dimensions: U(m×r), Σ(r×r), V^T(r×n)</li>
<li>Visual: Trimmed matrices, only rank-r portion</li>
<li>Use case: Efficient storage, exact reconstruction</li>
<li>
<p>Memory: O(mr + r² + rn)</p>
</li>
<li>
<p>"Truncated SVD" column</p>
</li>
<li>Matrix dimensions: U(m×k), Σ(k×k), V^T(k×n)</li>
<li>Visual: Further trimmed to k components</li>
<li>Use case: Low-rank approximation, denoising</li>
<li>Memory: O(mk + k² + kn)</li>
<li>Note: "k &lt; r, approximate reconstruction"</li>
</ol>
<p>Interactive elements:
- Hover to see example with specific dimensions
- Click to see Python code for each form
- Toggle to show reconstruction error for truncated form</p>
<p>Visual style:
- Matrix blocks with dimension labels
- Color coding: kept components in blue, discarded in gray
- Singular values shown as bar chart below</p>
<p>Implementation: HTML/CSS/JavaScript with SVG matrices</p>
</details>
<h3 id="computing-svd">Computing SVD</h3>
<p>SVD is typically computed in two stages:</p>
<ol>
<li><strong>Bidiagonalization:</strong> Transform <span class="arithmatex">\(A\)</span> to bidiagonal form using Householder reflections</li>
<li><strong>Diagonalization:</strong> Apply the QR algorithm (or divide-and-conquer) to find singular values</li>
</ol>
<p>For an <span class="arithmatex">\(m \times n\)</span> matrix with <span class="arithmatex">\(m \geq n\)</span>:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Flops</th>
</tr>
</thead>
<tbody>
<tr>
<td>Full SVD</td>
<td><span class="arithmatex">\(2mn^2 + 11n^3\)</span></td>
</tr>
<tr>
<td>Compact SVD</td>
<td><span class="arithmatex">\(2mn^2 + 11n^3\)</span></td>
</tr>
<tr>
<td>Truncated SVD (randomized)</td>
<td><span class="arithmatex">\(O(mnk + (m+n)k^2)\)</span></td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Randomized SVD for Large Matrices</p>
<p>For very large matrices where only the top <span class="arithmatex">\(k\)</span> singular values are needed, randomized algorithms provide significant speedups. Libraries like <code>sklearn.decomposition.TruncatedSVD</code> implement these efficient methods.</p>
</div>
<h2 id="low-rank-approximation">Low-Rank Approximation</h2>
<p>One of the most powerful applications of SVD is <strong>low-rank approximation</strong>. Given a matrix <span class="arithmatex">\(A\)</span> with rank <span class="arithmatex">\(r\)</span>, the best rank-<span class="arithmatex">\(k\)</span> approximation (for <span class="arithmatex">\(k &lt; r\)</span>) is:</p>
<p><span class="arithmatex">\(A_k = \sum_{i=1}^{k} \sigma_i \mathbf{u}_i \mathbf{v}_i^T\)</span></p>
<h4 id="the-eckart-young-theorem">The Eckart-Young Theorem</h4>
<p>The truncated SVD provides the optimal low-rank approximation:</p>
<p><span class="arithmatex">\(A_k = \arg\min_{\text{rank}(B) \leq k} \|A - B\|_F\)</span></p>
<p>The approximation error is:</p>
<p><span class="arithmatex">\(\|A - A_k\|_F = \sqrt{\sigma_{k+1}^2 + \sigma_{k+2}^2 + \cdots + \sigma_r^2}\)</span></p>
<p><span class="arithmatex">\(\|A - A_k\|_2 = \sigma_{k+1}\)</span></p>
<p>This theorem justifies using truncated SVD for:</p>
<ul>
<li><strong>Image compression:</strong> Store only top <span class="arithmatex">\(k\)</span> singular components</li>
<li><strong>Noise reduction:</strong> Small singular values often correspond to noise</li>
<li><strong>Dimensionality reduction:</strong> Project data onto top <span class="arithmatex">\(k\)</span> principal directions</li>
<li><strong>Recommender systems:</strong> Approximate user-item matrices</li>
</ul>
<h4 id="diagram-image-compression-with-svd">Diagram: Image Compression with SVD</h4>
<iframe src="../../sims/svd-image-compression/main.html" height="552px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/svd-image-compression/main.html">Run the SVD Image Compression MicroSim Fullscreen</a></p>
<details>
<summary>Image Compression MicroSim</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Evaluate</p>
<p>Learning Objective: Understand how truncated SVD compresses images by observing the quality-storage tradeoff as k varies</p>
<p>Visual elements:
- Left panel: Original grayscale image (as matrix)
- Center panel: Reconstructed image using rank-k approximation
- Right panel: Difference image (error visualization)
- Bottom: Singular value spectrum (bar chart or line plot)
- Statistics display: compression ratio, PSNR, % variance captured</p>
<p>Interactive controls:
- Image selector (sample images or upload)
- Slider for rank k (1 to full rank)
- "Show Singular Values" toggle
- "Show Error Image" toggle
- "Compare Side-by-Side" view option</p>
<p>Default parameters:
- Sample grayscale image (256×256)
- Initial k = 50
- Canvas: responsive</p>
<p>Behavior:
- Real-time reconstruction as k changes
- Show compression ratio: k(m+n+1) / (m×n)
- Display percentage of Frobenius norm captured
- Highlight "elbow" in singular value plot
- Show time/memory comparison</p>
<p>Implementation: p5.js with image processing</p>
</details>
<h3 id="applications-of-low-rank-approximation">Applications of Low-Rank Approximation</h3>
<ol>
<li><strong>Recommender Systems (Netflix Problem)</strong></li>
<li>User-movie rating matrix is approximately low-rank</li>
<li>Missing entries predicted from low-rank factors</li>
<li>
<p><span class="arithmatex">\(R \approx UV^T\)</span> where <span class="arithmatex">\(U\)</span> = user factors, <span class="arithmatex">\(V\)</span> = item factors</p>
</li>
<li>
<p><strong>Latent Semantic Analysis (LSA)</strong></p>
</li>
<li>Term-document matrix decomposed via SVD</li>
<li>Captures semantic relationships between words</li>
<li>
<p>Precursor to modern word embeddings</p>
</li>
<li>
<p><strong>Principal Component Analysis (PCA)</strong></p>
</li>
<li>Centered data matrix <span class="arithmatex">\(X\)</span> decomposed as <span class="arithmatex">\(X = U\Sigma V^T\)</span></li>
<li>Principal components are columns of <span class="arithmatex">\(V\)</span></li>
<li>Variance along each PC is <span class="arithmatex">\(\sigma_i^2/(n-1)\)</span></li>
</ol>
<h2 id="numerical-rank-and-condition-number">Numerical Rank and Condition Number</h2>
<p>In exact arithmetic, rank is well-defined. In floating-point computation, small singular values may arise from noise rather than true rank deficiency.</p>
<h3 id="numerical-rank">Numerical Rank</h3>
<p>The <strong>numerical rank</strong> is the number of singular values larger than a threshold <span class="arithmatex">\(\epsilon\)</span>:</p>
<p><span class="arithmatex">\(\text{rank}_\epsilon(A) = |\{i : \sigma_i &gt; \epsilon\}|\)</span></p>
<p>Common choices for <span class="arithmatex">\(\epsilon\)</span>:</p>
<ul>
<li><span class="arithmatex">\(\epsilon = \max(m,n) \cdot \epsilon_{\text{machine}} \cdot \sigma_1\)</span></li>
<li><span class="arithmatex">\(\epsilon = \sqrt{\epsilon_{\text{machine}}} \cdot \sigma_1\)</span></li>
</ul>
<p>where <span class="arithmatex">\(\epsilon_{\text{machine}} \approx 2.2 \times 10^{-16}\)</span> for double precision.</p>
<h3 id="condition-number">Condition Number</h3>
<p>The <strong>condition number</strong> measures how sensitive a matrix computation is to perturbations:</p>
<p><span class="arithmatex">\(\kappa(A) = \frac{\sigma_1}{\sigma_r} = \|A\| \cdot \|A^{-1}\|\)</span></p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(\sigma_1\)</span> is the largest singular value</li>
<li><span class="arithmatex">\(\sigma_r\)</span> is the smallest non-zero singular value</li>
</ul>
<h4 id="interpretation">Interpretation</h4>
<table>
<thead>
<tr>
<th>Condition Number</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\kappa \approx 1\)</span></td>
<td>Well-conditioned (stable computation)</td>
</tr>
<tr>
<td><span class="arithmatex">\(\kappa \approx 10^k\)</span></td>
<td>Lose ~<span class="arithmatex">\(k\)</span> digits of accuracy</td>
</tr>
<tr>
<td><span class="arithmatex">\(\kappa = \infty\)</span></td>
<td>Singular matrix (not invertible)</td>
</tr>
</tbody>
</table>
<p>For solving <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span>, the relative error in the solution satisfies:</p>
<p><span class="arithmatex">\(\frac{\|\delta \mathbf{x}\|}{\|\mathbf{x}\|} \leq \kappa(A) \cdot \frac{\|\delta \mathbf{b}\|}{\|\mathbf{b}\|}\)</span></p>
<p>A small perturbation <span class="arithmatex">\(\delta \mathbf{b}\)</span> in the right-hand side can be amplified by <span class="arithmatex">\(\kappa(A)\)</span> in the solution.</p>
<h4 id="diagram-condition-number-visualizer">Diagram: Condition Number Visualizer</h4>
<iframe src="../../sims/condition-number/main.html" height="502px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/condition-number/main.html">Run the Condition Number Visualizer Fullscreen</a></p>
<details>
<summary>Condition Number and Sensitivity Visualizer</summary>
<p>Type: microsim</p>
<p>Bloom Taxonomy Level: Evaluate</p>
<p>Learning Objective: Understand how condition number affects solution sensitivity by perturbing linear systems</p>
<p>Visual elements:
- Left panel: 2D visualization of linear system Ax = b
  - Two lines representing equations
  - Intersection point (solution)
  - Perturbation region around b
  - Resulting uncertainty region around x
- Right panel: Singular value bar chart
  - σ₁ and σ₂ (or more) as bars
  - Condition number κ = σ₁/σ₂ displayed
- Matrix A and vectors b, x displayed</p>
<p>Interactive controls:
- 2x2 matrix input
- Slider to control perturbation magnitude ε
- "Add Random Perturbation" button
- Toggle between well-conditioned and ill-conditioned examples
- Show/hide uncertainty ellipse</p>
<p>Default parameters:
- Well-conditioned example: A = [[2, 0], [0, 2]] (κ = 1)
- Ill-conditioned example: A = [[1, 1], [1, 1.0001]] (κ ≈ 10000)
- Canvas: responsive</p>
<p>Behavior:
- Show how nearly parallel lines (ill-conditioned) create large uncertainty
- Animate perturbations and show solution movement
- Display digits of accuracy lost
- Compare κ calculation methods</p>
<p>Implementation: p5.js with geometric visualization</p>
</details>
<h3 id="improving-conditioning">Improving Conditioning</h3>
<p>Several techniques can improve numerical conditioning:</p>
<ul>
<li><strong>Preconditioning:</strong> Transform <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span> to <span class="arithmatex">\(M^{-1}A\mathbf{x} = M^{-1}\mathbf{b}\)</span> where <span class="arithmatex">\(M \approx A\)</span></li>
<li><strong>Regularization:</strong> Replace <span class="arithmatex">\(A^TA\)</span> with <span class="arithmatex">\(A^TA + \lambda I\)</span> (ridge regression)</li>
<li><strong>Scaling:</strong> Equilibrate row and column norms of <span class="arithmatex">\(A\)</span></li>
</ul>
<h2 id="choosing-the-right-decomposition">Choosing the Right Decomposition</h2>
<p>The choice of decomposition depends on the matrix structure and application:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code>Is A square?
├── Yes: Is A symmetric positive definite?
│   ├── Yes: Use Cholesky (fastest, most stable)
│   └── No: Use LU with partial pivoting
│
└── No (rectangular): What&#39;s the goal?
    ├── Least squares: Use QR
    ├── Low-rank approximation: Use SVD
    └── Eigenvalue-like analysis: Use SVD
</code></pre></div></td></tr></table></div>
<table>
<thead>
<tr>
<th>Application</th>
<th>Recommended Decomposition</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td>Solve <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span> (multiple <span class="arithmatex">\(\mathbf{b}\)</span>)</td>
<td>LU</td>
<td>Factor once, solve many</td>
</tr>
<tr>
<td>Solve <span class="arithmatex">\(A\mathbf{x} = \mathbf{b}\)</span> (<span class="arithmatex">\(A\)</span> SPD)</td>
<td>Cholesky</td>
<td>Half the work, more stable</td>
</tr>
<tr>
<td>Least squares</td>
<td>QR</td>
<td>Numerically stable</td>
</tr>
<tr>
<td>Eigenvalues (symmetric)</td>
<td>QR algorithm on tridiagonal form</td>
<td>Standard method</td>
</tr>
<tr>
<td>Singular values</td>
<td>SVD via bidiagonalization</td>
<td>Definitive answer</td>
</tr>
<tr>
<td>Low-rank approximation</td>
<td>Truncated SVD</td>
<td>Optimal by Eckart-Young</td>
</tr>
<tr>
<td>Matrix rank</td>
<td>SVD</td>
<td>Count significant <span class="arithmatex">\(\sigma_i\)</span></td>
</tr>
</tbody>
</table>
<h4 id="diagram-decomposition-decision-tree">Diagram: Decomposition Decision Tree</h4>
<iframe src="../../sims/decomposition-guide/main.html" height="532px" width="100%" scrolling="no"></iframe>

<p><a class="md-button md-button--primary" href="../../sims/decomposition-guide/main.html">Run the Decomposition Selection Guide Fullscreen</a></p>
<details>
<summary>Matrix Decomposition Selection Guide</summary>
<p>Type: workflow</p>
<p>Bloom Taxonomy Level: Evaluate</p>
<p>Learning Objective: Guide students to select the appropriate matrix decomposition based on matrix properties and application needs</p>
<p>Visual style: Interactive decision tree flowchart</p>
<p>Steps:
1. Start: "Given matrix A, what do you need?"
   Hover text: "First consider your goal and matrix properties"</p>
<ol>
<li>Decision: "Goal?"</li>
<li>"Solve linear system" → Branch A</li>
<li>"Least squares / overdetermined" → Branch B</li>
<li>"Low-rank approximation" → Branch C</li>
<li>"Eigenvalues" → Branch D</li>
</ol>
<p>3a. Decision: "Is A symmetric positive definite?"
    - Yes → "Use Cholesky LL^T"
      Hover text: "Fastest, half the flops of LU"
    - No → "Use LU with pivoting"
      Hover text: "Works for any invertible matrix"</p>
<p>3b. Process: "Use QR Decomposition"
    Hover text: "More stable than normal equations"</p>
<p>3c. Process: "Use Truncated SVD"
    Hover text: "Optimal rank-k approximation by Eckart-Young"</p>
<p>3d. Decision: "Is A symmetric?"
    - Yes → "Eigendecomposition via QR algorithm"
    - No → "Consider SVD for singular values"</p>
<p>Color coding:
- Blue: Decision nodes
- Green: Recommended decompositions
- Orange: Computation nodes
- Gray: Information nodes</p>
<p>Interactive:
- Click nodes to see code examples
- Hover for complexity information
- Links to relevant sections</p>
<p>Implementation: D3.js or Mermaid.js with interaction handlers</p>
</details>
<h2 id="practical-implementation">Practical Implementation</h2>
<p>Here is how to use these decompositions in Python:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>

<span class="c1"># Sample matrices</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># LU Decomposition (with pivoting)</span>
<span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">x_lu</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">U</span><span class="p">,</span>
       <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">P</span> <span class="o">@</span> <span class="n">b</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Cholesky (if A is positive definite)</span>
<span class="n">L_chol</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x_chol</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cho_solve</span><span class="p">((</span><span class="n">L_chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># QR Decomposition</span>
<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">x_qr</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="c1"># Solve via pseudoinverse</span>
<span class="n">x_svd</span> <span class="o">=</span> <span class="n">Vh</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">U</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">b</span>

<span class="c1"># Condition number</span>
<span class="n">cond</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Condition number: </span><span class="si">{</span><span class="n">cond</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Low-rank approximation</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># rank of approximation</span>
<span class="n">A_k</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span> <span class="o">@</span> <span class="n">Vh</span><span class="p">[:</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">A_k</span><span class="p">,</span> <span class="s1">&#39;fro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank-</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> approximation error: </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="summary_1">Summary</h2>
<p>This chapter covered the four essential matrix decompositions:</p>
<p><strong>LU Decomposition:</strong></p>
<ul>
<li>Factors <span class="arithmatex">\(A = LU\)</span> (with pivoting: <span class="arithmatex">\(PA = LU\)</span>)</li>
<li>Used for solving linear systems efficiently</li>
<li>Cost: <span class="arithmatex">\(\frac{2}{3}n^3\)</span> flops to factor, <span class="arithmatex">\(2n^2\)</span> per solve</li>
</ul>
<p><strong>Cholesky Decomposition:</strong></p>
<ul>
<li>Factors <span class="arithmatex">\(A = LL^T\)</span> for symmetric positive definite matrices</li>
<li>Half the cost of LU, no pivoting needed</li>
<li>Positive definite means all eigenvalues positive, <span class="arithmatex">\(\mathbf{x}^TA\mathbf{x} &gt; 0\)</span></li>
</ul>
<p><strong>QR Decomposition:</strong></p>
<ul>
<li>Factors <span class="arithmatex">\(A = QR\)</span> with orthogonal <span class="arithmatex">\(Q\)</span></li>
<li>Foundation for least squares and eigenvalue algorithms</li>
<li>Gram-Schmidt (intuitive) vs. Householder (stable)</li>
</ul>
<p><strong>Singular Value Decomposition:</strong></p>
<ul>
<li>Factors <span class="arithmatex">\(A = U\Sigma V^T\)</span> for any matrix</li>
<li>Singular values reveal matrix structure and rank</li>
<li>Truncated SVD gives optimal low-rank approximation</li>
</ul>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Matrix rank</strong> determines decomposition structure</li>
<li><strong>Numerical rank</strong> accounts for floating-point limitations</li>
<li><strong>Condition number</strong> <span class="arithmatex">\(\kappa = \sigma_1/\sigma_r\)</span> measures sensitivity</li>
</ul>
<p><strong>Practical Guidelines:</strong></p>
<ol>
<li>Use Cholesky for symmetric positive definite systems</li>
<li>Use LU for general square systems (with pivoting!)</li>
<li>Use QR for least squares problems</li>
<li>Use SVD for low-rank approximation and dimensionality reduction</li>
<li>Always check condition number before trusting numerical results</li>
</ol>
<details class="question">
<summary>Self-Check: When would you choose SVD over QR for a least squares problem?</summary>
<p>SVD is preferred when the matrix is rank-deficient or nearly rank-deficient (ill-conditioned). QR can fail or give unstable results when columns are nearly linearly dependent, while SVD explicitly reveals the rank through singular values and handles rank deficiency gracefully via the pseudoinverse. SVD also provides the minimum-norm solution when multiple solutions exist.</p>
</details>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../06-eigenvalues-and-eigenvectors/quiz/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Quiz">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
          </a>
        
        
          
          <a href="quiz/" class="md-footer__link md-footer__link--next" aria-label="Next: Quiz">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Quiz
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.expand", "navigation.path", "navigation.prune", "navigation.indexes", "toc.follow", "navigation.top", "navigation.footer", "content.action.edit"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="../../js/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>